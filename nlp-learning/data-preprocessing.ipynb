{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b5f9a8-61fb-4c3b-bc90-6b76f4948a44",
   "metadata": {},
   "source": [
    "# First step of preprocessign data is to convert it to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3cd118c-3a52-482d-8468-9afb073c9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Her cat's name is Luna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5133b7b0-3136-4489-93cd-96d4a2038aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_sentence = sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fca1d3-7471-4e3d-9c94-2e2a9256a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her cat's name is luna\n"
     ]
    }
   ],
   "source": [
    "print(lower_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3417c4ec-9584-4832-8b92-3127201d5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = ['Could you pass me the remote?',\n",
    "    'TIMES SQUARE is a great place for New Year',\n",
    "    'Dinner is ready now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "278e6a11-637d-4843-9f62-9c95a5d3654d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could you pass me the remote?\n"
     ]
    }
   ],
   "source": [
    "print(sentence_list[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "821784fb-6cf8-40f9-a2ec-7a36ca1c4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_sentence_list = [x.lower() for x in sentence_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65efeea7-5580-4ef3-8f4e-c20e053651fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['could you pass me the remote?', 'times square is a great place for new year', 'dinner is ready now']\n"
     ]
    }
   ],
   "source": [
    "print(lower_sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ded935-f68c-4e28-8fc0-a3891a45acf2",
   "metadata": {},
   "source": [
    "# Second step of preprocessing is to remove stop words - common words that dont carry meaning. this removes complexity from teh data to have a smaller cleaner dataset. Speeds the accuraracy and improves processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1919617b-0f53-4aa0-bc63-3ca4ec88a933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Lakshmi.Janardhanan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23266818-dcc1-49f5-bcfb-41b9c41bfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06bee10f-9892-4040-bf2f-de12bb5fa75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a45d3a7-b435-48f4-b19d-83161f975ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \" it was too far to go to the shop and he did not want her to walk \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14955c06-2989-4e12-ae37-5b8ce69fc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_no_stopwords = ' '.join( word for word in sentence.split() if word not in en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e097bc18-cf2e-44ed-adbc-204cc13fbe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "far go shop want walk\n"
     ]
    }
   ],
   "source": [
    "print(sentence_no_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4837b822-8e0d-45d2-a60f-c46c6b0bfbfe",
   "metadata": {},
   "source": [
    "# Regular expressions to match patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c730badf-7ce5-4c15-b1b1-693868d16344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c4d53-051b-433c-96cb-5c2b39163a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using r treates it as a raw string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37a9ea87-3a42-4d76-bc87-fc5d5264a143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\desktop\\notes\n"
     ]
    }
   ],
   "source": [
    "my_folder = r'C:\\desktop\\notes'\n",
    "print(my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87c3d02f-ae40-4100-92e8-73c82a4e00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_search = re.search('pattern', r'string to find the pattern') # to find a certain pattern in the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2e81498-1515-4584-92d2-0dd03c82e1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(19, 26), match='pattern'>\n"
     ]
    }
   ],
   "source": [
    "print(result_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9253662-c9c4-4208-8ed7-c2caca78e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Replace the design here\n"
     ]
    }
   ],
   "source": [
    " print(re.sub('pattern', 'design',' Replace the pattern here')) # replacing one string by another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a7af6f1-c5e5-4655-b803-a7d5c931c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_reviews=[ 'Sam\\'s very helpful',\n",
    "                  'Jane went above and beyond',\n",
    "                  'I could\\'nt have found what i wanted without Eddie',\n",
    "                  'a cashier was very pleasant',\n",
    "                  'Lucy is a great addition to the team',\n",
    "                  'The store was stocjed well by Eddie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06695da0-d698-4146-9860-6be98e52075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final all the Eddie Reviews from the list\n",
    "Eddie_reviews =[]\n",
    "pattern = r'Eddie?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "494596b6-650c-48ae-8425-ae693922a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in customer_reviews:\n",
    "    if re.search(pattern, string):\n",
    "        Eddie_reviews.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ebc51622-d1e8-4c9f-98bd-45d53f186f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I could not have found what i wanted without Eddie', 'The store was stocjed well by Eddie']\n"
     ]
    }
   ],
   "source": [
    "print(Eddie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8b664-eff5-41f8-935a-c284b7268cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the reviews that start with the letter a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "98dc151c-b745-4826-ab4d-a62beb065f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reviews = []\n",
    "pattern_a = r\"^a\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3fd3101b-7d0a-4098-8292-9ecf5632716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a cashier was very pleasant']\n"
     ]
    }
   ],
   "source": [
    "for string in customer_reviews:\n",
    "    if (re.search(pattern_a, string )):\n",
    "        a_reviews.append(string)\n",
    "\n",
    "print(a_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36546a7e-7c8f-4a13-9d1f-44f237fdc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find reviews that end with the letter e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d26e22fb-8394-45a0-b91b-630be11c2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_reviews = []\n",
    "pattern_e = r'e$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "61c15a98-ea9c-4f43-a82e-3788c4d413d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I could not have found what i wanted without Eddie', 'The store was stocjed well by Eddie']\n"
     ]
    }
   ],
   "source": [
    "for string in customer_reviews:\n",
    "    if(re.search(pattern_e, string)):\n",
    "        e_reviews.append(string)\n",
    "\n",
    "print(e_reviews)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74224a2a-0e7b-4846-9be6-6b7ff8ff9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the reviews that have very or above in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a05d2edd-a0f0-445b-b4c1-46f9d98f8c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sam was very helpful', 'Jane went above and beyond', 'a cashier was very pleasant']\n"
     ]
    }
   ],
   "source": [
    "very_above_reviews = []\n",
    "pattern_va = r'very|above'\n",
    "\n",
    "for string in customer_reviews:\n",
    "    if (re.search(pattern_va, string)):\n",
    "        very_above_reviews.append(string)\n",
    "\n",
    "print(very_above_reviews)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f5f2f3-8739-4399-9301-fd3bc4ed15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuations from the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "87fb8960-ca11-483e-9b3a-814af9d25a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sams very helpful', 'Jane went above and beyond', 'I couldnt have found what i wanted without Eddie', 'a cashier was very pleasant', 'Lucy is a great addition to the team', 'The store was stocjed well by Eddie']\n"
     ]
    }
   ],
   "source": [
    "no_punct_reviews = []\n",
    "pattern_to_find = r\"[^\\w\\s]\"\n",
    "for string in customer_reviews:\n",
    "    string1 =re.sub(pattern_to_find,'',string)\n",
    "    no_punct_reviews.append(string1)\n",
    "\n",
    "print(no_punct_reviews)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549f6cb-d030-4a5c-96d9-59f6a9d7e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Tokenization. Usually indvidual words are tokens, they can also be sentences, chars etc depending on your usecase.\n",
    "#  This is a step before vectorizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb51c2-100b-4d3b-8c3c-aba2f8cf7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk is a natural languange processing libraries for analyzing and processing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bb669216-6307-4a7c-aa4b-bd998bcfa99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Lakshmi.Janardhanan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/Lakshmi.Janardhanan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6db406eb-70d6-4771-a70c-35a2f042a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"Her cat's name is Luna. Her dog's name is Max.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aaba3ca5-9e7b-48af-86c2-038a33ec6c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Her cat's name is Luna.\", \"Her dog's name is Max.\"]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2c24688b-c31e-439d-8f4b-dd89c4a2e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Her', 'cat', \"'s\", 'name', 'is', 'Luna']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \" Her cat's name is Luna\"\n",
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c34f92-9810-400f-b4c8-eca07ae3d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step in processing : Standardize the text using stemming viz, reducing to the base form - connecting to connect\n",
    "# Reduces number of unique words in our dataset therefore reducign size and complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7af02a5f-150f-4686-a1d5-c62a57adb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ae5ced14-2622-456e-9aa4-3bb0b214b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "92a1aae7-dee0-478a-98f5-9ba49b587464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting : connect\n",
      "connected : connect\n",
      "connectivity : connect\n",
      "connects : connect\n",
      "connect : connect\n"
     ]
    }
   ],
   "source": [
    "connect_tokens = [\"connecting\", \"connected\", \"connectivity\", \"connects\", \"connect\"]\n",
    "for t in connect_tokens:\n",
    "    print(t, \":\", ps.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca24515-6d25-464d-97bd-50ce5c408814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice in the example below, the base word for learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "33e993e6-7b70-47f0-a645-58eb4d74d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_tokens = ['learned', 'learning', 'learned', 'learns', 'learner', 'learners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "062f3575-a92e-4544-b792-fce3e10d41c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned : learn\n",
      "learning : learn\n",
      "learned : learn\n",
      "learns : learn\n",
      "learner : learner\n",
      "learners : learner\n"
     ]
    }
   ],
   "source": [
    "for t in learn_tokens:\n",
    "    print(t, \":\", ps.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13840237-7613-4faa-b3cc-6ed4b23bccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the example below, some words are reduced down to the base words that arent proper words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d3f9b6a7-3d53-4971-815e-1c64e36ab8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_tokens = ['likes', 'better', 'worse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "efa0c0f8-126e-4fab-a2d0-f40babbb8da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes : like\n",
      "better : better\n",
      "worse : wors\n"
     ]
    }
   ],
   "source": [
    "for t in likes_tokens:\n",
    "    print(t, \":\", ps.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc13931-ea77-4dc6-a2e6-c3f5259144c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming trims the last few chars and lemmitization reduces the word to its base word without losign its meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "eeaa0c2f-26c2-487f-b5bb-a613e0a8dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Lakshmi.Janardhanan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9c3379a3-2d1c-4ebd-8387-ef709cda6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ce9d6a5e-4eb2-4746-8274-cb5a71acbeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting : connecting\n",
      "connected : connected\n",
      "connectivity : connectivity\n",
      "connects : connects\n",
      "connect : connect\n"
     ]
    }
   ],
   "source": [
    "for t in connect_tokens:\n",
    "    print(t, \":\", lm.lemmatize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "372367d0-b4a6-4495-8443-40f41c1c997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned : learned\n",
      "learning : learning\n",
      "learned : learned\n",
      "learns : learns\n",
      "learner : learner\n",
      "learners : learner\n"
     ]
    }
   ],
   "source": [
    "for t in learn_tokens:\n",
    "    print(t, \":\", lm.lemmatize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4fe05eb8-fe5c-4f7c-a7c9-45dfd29c7f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes : like\n",
      "better : better\n",
      "worse : worse\n"
     ]
    }
   ],
   "source": [
    "for t in likes_tokens:\n",
    "    print(t, \":\", lm.lemmatize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fff779-f669-41ba-b91b-93abe5d5054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N Grams - A sequence of neighboring n words or tokens where n can be any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9e6df007-57ea-4ab3-9145-2ee60c56e1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 13:58:59.191 system_profiler[98619:2641488] XType: font daemon returned 0 fonts!\n",
      "2024-12-24 13:58:59.193 system_profiler[98619:2641488] registering /System/Library/Fonts/*, /System/Library/Fonts/Base/*, and /System/Library/Fonts/Supplemental/* locally\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52b756-b739-44d2-9001-c17a075a68d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
