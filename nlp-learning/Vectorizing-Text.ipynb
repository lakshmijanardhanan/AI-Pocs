{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72aea5a-ba47-4941-9804-b07d690469b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorixing text means converting it into numerical representations so that the machine learning model can understand them\n",
    "# Two ways of doing this\n",
    "# Bag of words model\n",
    "# Term frequency Inverse Document frequency (TF IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a3f76-832a-4fb4-b895-a18efd204a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag od words model is simple. It counts which our words appear in which of our document. it doesnt take into account the order of words\n",
    "# or how many times the words appear in different documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb0f78-9802-46d6-8121-5df113bbf961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF IDF captures a little bit more about context. IT calculates the importance of that word for that particular document and also calculates\n",
    "# how that word appears in each of the other documents in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7e35c6-3b45-4a6c-a7a0-0f2915413639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8df198e-c29c-4207-908f-d4323c69110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [' Most shark attacks occur about 10 feet from the beach since that is where the people are',\n",
    "        'the efficiency with which he paired the socks in the drawer was quite admirable',\n",
    "        'carol drank the blood as if she were a vampire',\n",
    "        'giving directions that the mountains are to the west only works when you can see them',\n",
    "        'the sign said there was road work ahead so he decided to speed up',\n",
    "        'the gruff old man sat in the back of the bait shop grumbling to himself as he scooped out a handful of worms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5dbaf8c-8532-4f2f-ab51-8ec92829aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ab3eb-e858-420d-be72-b00d2536fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f393eaa-04ef-4473-a690-9fe3b36968b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec_fit = countvec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1577ba9f-a211-424d-b29b-70d2775dec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame(countvec_fit.toarray(), columns=countvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4b5263d-3f47-4a96-9939-1d7e84938de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10  about  admirable  ahead  are  as  attacks  back  bait  beach  ...  \\\n",
      "0   1      1          0      0    1   0        1     0     0      1  ...   \n",
      "1   0      0          1      0    0   0        0     0     0      0  ...   \n",
      "2   0      0          0      0    0   1        0     0     0      0  ...   \n",
      "3   0      0          0      0    1   0        0     0     0      0  ...   \n",
      "4   0      0          0      1    0   0        0     0     0      0  ...   \n",
      "5   0      0          0      0    0   1        0     1     1      0  ...   \n",
      "\n",
      "   were  west  when  where  which  with  work  works  worms  you  \n",
      "0     0     0     0      1      0     0     0      0      0    0  \n",
      "1     0     0     0      0      1     1     0      0      0    0  \n",
      "2     1     0     0      0      0     0     0      0      0    0  \n",
      "3     0     1     1      0      0     0     0      1      0    1  \n",
      "4     0     0     0      0      0     0     1      0      0    0  \n",
      "5     0     0     0      0      0     0     0      0      1    0  \n",
      "\n",
      "[6 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cc554-77a7-49ae-8dfe-3fa2a20d40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row is each of the line of text in the data. Column is one of the individual words that is present in all the data\n",
    "# Values are 0 and 1 which indicates it is present or not. All context is however lost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2f518-00e1-4272-95dd-01c0fcc6bb8d",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbde083-0bdc-4e82-a8ce-1ad2ef2cef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency is the number of times a word appears in a document. It is calculated by number of times the term appears in document\n",
    "# divided by total number of items in that document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026265e-0b9b-460a-9891-f5a0a90d134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF measure of importance of each term in each document. it is calculated by log of total number of documents / number of \n",
    "# documents containing the term. For example, it could be the number of rows in dataset / number of rows that contain the \n",
    "# specific term we are looking at. This then iterates through each term in each of the document and calculates a score for each term\n",
    "# Common words have lower score and less important. Higher score for less common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b987d56-e750-4947-b95f-8c65df0d0618",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50cb2bcd-35fe-4c04-9a3d-9ab6b71a3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37e94e1d-6805-4bd4-9243-ff7e53b18754",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec_fit = tfidfvec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96aea657-a32e-49b7-b1b0-9750aeed49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_bag = pd.DataFrame(tfidfvec_fit.toarray(), columns=tfidfvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fba53a4-cf57-43ac-977c-4e48e645f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10     about  admirable     ahead       are        as   attacks  \\\n",
      "0  0.257061  0.257061   0.000000  0.000000  0.210794  0.000000  0.257061   \n",
      "1  0.000000  0.000000   0.293641  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000   0.000000  0.000000  0.000000  0.292313  0.000000   \n",
      "3  0.000000  0.000000   0.000000  0.000000  0.222257  0.000000  0.000000   \n",
      "4  0.000000  0.000000   0.000000  0.290766  0.000000  0.000000  0.000000   \n",
      "5  0.000000  0.000000   0.000000  0.000000  0.000000  0.178615  0.000000   \n",
      "\n",
      "      back     bait     beach  ...      were     west     when     where  \\\n",
      "0  0.00000  0.00000  0.257061  ...  0.000000  0.00000  0.00000  0.257061   \n",
      "1  0.00000  0.00000  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "2  0.00000  0.00000  0.000000  ...  0.356474  0.00000  0.00000  0.000000   \n",
      "3  0.00000  0.00000  0.000000  ...  0.000000  0.27104  0.27104  0.000000   \n",
      "4  0.00000  0.00000  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "5  0.21782  0.21782  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "\n",
      "      which      with      work    works    worms      you  \n",
      "0  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  \n",
      "1  0.293641  0.293641  0.000000  0.00000  0.00000  0.00000  \n",
      "2  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  \n",
      "3  0.000000  0.000000  0.000000  0.27104  0.00000  0.27104  \n",
      "4  0.000000  0.000000  0.290766  0.00000  0.00000  0.00000  \n",
      "5  0.000000  0.000000  0.000000  0.00000  0.21782  0.00000  \n",
      "\n",
      "[6 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfid_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c52caf8-28f2-41ba-8a1d-ed656ee504fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is more context info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
