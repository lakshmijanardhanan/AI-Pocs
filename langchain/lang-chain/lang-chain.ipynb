{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152b017-6ac9-46ac-b225-f77df39b3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "# Langchain - framework for creating application powered by llms that are stateful, context aware and can reason.\n",
    "# stateful - keeping memories of past or ongoing conversations\n",
    "# context awareness - answering questions about information outside model's training data\n",
    "#reasoning - chose various tools and their order of execution to solve a specific task.\n",
    "# Usecases : Summarizing news, query db, multi source fact checker, integrate chat platform to answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3579f-1f48-42d3-8177-7ef24cd8b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business application \n",
    "#Ally Financial - Bank/ Car insurance company developed Ally AI - summarizes all conversation between associates and customers freeing them\n",
    "#from documentation. sharing sensitive information is an issue cannot be shared directly with chat gpt. We need a bridge that masks this info\n",
    "#Lang Chain has a module to mask sensitive information before making the llm call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6239b8a-0953-482e-8d42-36f5c310126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adyen is a fintech platform used by MSFT, spotify and LinkedIN. It provided end to end payment services, data insights etc. To improve\n",
    "# support and customer service they wan to reduce response waiting time by implementing a smart routing ticketing systme.\n",
    "# Also including automatic llm powered responses. Solving for the time it takes to redirect a ticket.\n",
    "# Using RAG or Retrieval Augmented Generation for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3223f-6239-42f8-87a1-b609cf744f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robocorp - created bots to automate tasks - Ex: Automate scraping of prices, reviews and info from website. Monthly processing of invoices\n",
    "# onboarding of new team members, automate the generation of financial reports,  IT can create robots to test applications and websites.\n",
    "# ReboCorp uses Langchain to create Remark that can copilot / generate code snippets for you. Explain the usecase in human language and Remark\n",
    "# will develop the code. Coding examples and documentatation used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86527d84-3668-4f64-97a0-d1e4721b5ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Langchain's integration with GPT4. You can experiment with other models Anthropic's Claude or Google's Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3107f-bfdd-4557-9134-6dfed8946e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLms are inherently stateless, we need to store the conversations thus far, langchain has a module for that\n",
    "# context awareness - Langchain has many document loaders to load data. It has several integrations with databases, vector stores\n",
    "# Reasoning - Langchain has integrate many tools such as Wikipedia, Wolfram Alpha, Bing, DuckDuckGo, Google, Google Drive\n",
    "# LAngSmith for observability to inspect, monitor and monitor your product\n",
    "# dEployment - LangSmith allows you to deploy your model as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77201f-169c-4dd2-bf21-9b9be6751871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of text we pass to llm counts as tokens. OpeAI pricing is based on token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49816c-e93a-4abf-861c-b46ee66487a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure of a langchain project\n",
    "# Chatmessages, chat templates, chat prompting. Asking a chatbot a question and getting the desired response\n",
    "#Creating a stateful chatput\n",
    "# converting the llm model output to different data types that can be fed into applications - string, list , datetime\n",
    "#Langchain expression language LCEL  which is the protocol for implmeneting LLM applications\n",
    "# Retreieval Augmented generation, feeding custom data to the model, data that it hasnt been previously trained on to generate context specific answers\n",
    "# Agent tooling - tools give access to browse internet,execute code, solve math problems. An agent shose sright tools for a problem giving \n",
    "# chatbot ability to reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce23abf-708a-452d-a17b-ea8a2cd8bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens usually correspond to 3/4 of a word. 100 tokens correspond to 75 words not necessarily a word or char. Rather a sequences of char\n",
    "# frequently seen together. the task of a model is to understand the statistical relationship between the tokens in the vocab\n",
    "# it is then able to predict statistically the next token that is likely to occur next in the sentence.\n",
    "# size of token is tradeoff between vocab size, efficieny, semantic meaning, performance\n",
    "#https://platform.openai.com/tokenizer\n",
    "# A token at the begining of the snetence does not have a prceeding space where as at the end the of the token, there may be a space and hence\n",
    "# the same words can have different ides. \"What\" are the beginning of the sentence can indicate a question\n",
    "# OpenAI pricing. GPT-40  price depdends on input and output. 1M tokens corresponds to 1500 page nove for input. \n",
    "#Each model has a certain context window limit. GPT-40 is 128,000 tokens shared between input and output (you cannot dump 1M token novel input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e500fa-db97-4839-9c41-b2d596f0c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding models are those that capture text as numerical vectors that capture its semantic meanings\n",
    "#text-embedding-3-small, text-embedding-3-large, ada v2\n",
    "# fine tuning, image and audio models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce8144-7ba9-4756-8376-7094a9ad7bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8fe279-2bdf-4505-98ec-aba3f5235349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
