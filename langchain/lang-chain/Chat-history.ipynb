{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d50c30c-99b1-449b-83e5-fa2c2e1fc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e8fa7-73ce-4497-b4e1-d53b58390574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0daf8e0-7396-4d95-95c2-b3abe885c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ( ChatPromptTemplate, ChatMessagePromptTemplate, HumanMessagePromptTemplate)\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058eab83-dbfa-473c-bb3c-6e92122d03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.chat_message_histories. Cant find ChatMessageHistory here, is deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa5ca82-9877-4c94-bee8-ae21565db92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95699e38-5ec5-44a6-9ccf-435a47d822eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI ( model='gpt-4', \n",
    "                   seed=365 , \n",
    "                   temperature=0, \n",
    "                   max_completion_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11ef80d6-d083-4051-aed7-921b4f93457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b38a94d-43d9-471b-9b2b-b9f0f331ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_history.add_user_message('Can you give me an interesting fact that i did not know about')\n",
    "chat_message_history.add_ai_message('Sure, did you know that the longest place name on this planet is 85 letters long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "128b6430-ee33-44c9-9c9f-83cf22f7b6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Can you give me an interesting fact that i did not know about', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure, did you know that the longest place name on this planet is 85 letters long', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f0804-6bae-412c-8925-2ac39493ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be easily integrated with lang chain memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889a87e-0fc4-46d5-8f28-8e873de73526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advantage of using the ChatMessageHistory versus a python list for storing human and ai messages. Adv converting to various formats,\n",
    "# quickly clearing chat histories, integrating with langchain memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b46bcaa-f81c-4d2f-9a36-e5e541b2c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_h = HumanMessagePromptTemplate.from_template(template = '{follow-up question}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c57ae44-87c5-4376-a842-10debb5c216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(chat_message_history.messages + [message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "affcb67b-30ad-4f66-a940-fd686f5026c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['follow-up question'], input_types={}, partial_variables={}, messages=[HumanMessage(content='Can you give me an interesting fact that i did not know about', additional_kwargs={}, response_metadata={}), AIMessage(content='Sure, did you know that the longest place name on this planet is 85 letters long', additional_kwargs={}, response_metadata={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['follow-up question'], input_types={}, partial_variables={}, template='{follow-up question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db6d8f57-b282-4352-b39d-da7f411d3f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/z4lt05n13lggvkf4cntq7dc40000gr/T/ipykernel_42674/3887436020.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=chat, prompt=chat_template)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c69d2670-75f7-4a79-a9ab-246a3c4292ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'follow-up question':'What is the name?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8a0280c-dd8b-40c2-9ec5-d7cbf7d5ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the place is \"Taumatawhakatangi足hangakoauauotamatea足turipukakapikimaunga足horonukupokaiwhen足uakitanatahu.\" It's a hill in New Zealand.\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db545729-4b67-4d00-a3bd-28526eb297f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({'follow-up question':'What does the name mean ?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "400d19e7-58ef-427a-a847-3b5e5abbf98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name is \"Taumatawhakatangihangakoauauotamateaturipukakapikimaungahoronukupokaiwhenuakitanatahu,\" a hill in New Zealand. The name roughly translates to \"The summit where Tamatea, the man with the big knees, the slider, climber of mountains, the land-swallower who travelled about, played his nose flute to his loved one\" in English.\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebb35509-0133-4ed7-a6c0-9717ddf2b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TheChatMessageHistory class is suitable for situations where we need to manage history messages outside a chain\n",
    "# When recollecting messages from the current conversation, we should instead turn to memory classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087682c-8f08-4a8d-a0d3-a9280406186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start having memory to a chat, one basic approach is to store the new human and AI messages with the old ones and feed the entire\n",
    "# conversation on the next invoke using Conversation Buffer Memory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d01ac437-9bca-4dba-bb03-ec6b55679de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.globals import set_verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9935817-f303-486a-9a44-3f2f854232ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_verbose helps with better monitoring of the process and debugging\n",
    "set_verbose(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8c63ced2-14a0-4e63-bbbb-bb348dee579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_s_m = SystemMessage(content = '''The chatbot should reluctantly answer questions with sarcastic responses. ''')\n",
    "message_template_h_m = HumanMessagePromptTemplate.from_template(template = '''{question}''')\n",
    "messages_history_m = MessagesPlaceholder( variable_name='message_log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78d0d02f-c956-402d-a75b-ae33cb2da252",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_m =ChatPromptTemplate.from_messages([message_s_m, messages_history_m, message_template_h_m])\n",
    "# here order is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "973d3b01-6eca-4b22-b2a6-0bf3361ab529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['message_log', 'question'], input_types={'message_log': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x111f91120>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessage(content='The chatbot should reluctantly answer questions with sarcastic responses. ', additional_kwargs={}, response_metadata={}), MessagesPlaceholder(variable_name='message_log'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b72be60f-b66f-494e-8090-0d113ea3ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_info = ChatMessageHistory()\n",
    "background_info.add_user_message('Hi!')\n",
    "background_info.add_ai_message(\"You really know how to make an entrance, dont you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "016b29e6-9ab4-486e-a86e-0b73c1d61db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ite time to create a memory object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cb4082a5-1d7f-4296-ad2f-f21b7a434b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_memory = ConversationBufferMemory( memory_key='message_log', chat_memory= background_info, return_messages=True)\n",
    "# Returns the memory as a list of chat messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b58194e7-cbbe-4deb-a780-a9a3524c9713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='You really know how to make an entrance, dont you?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "55e2f519-5e3a-40e0-a4d0-ed579a409849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}), AIMessage(content='You really know how to make an entrance, dont you?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(chat_memory.load_memory_variables({})['message_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cf9f9-b89f-4d58-a782-83304c6fada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to feed all the components, the chat, the chat prompt template and the conversation buffer memory into an LLM chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "11eef3a5-3483-4597-9194-831f90802c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lchain = LLMChain( llm =chat, prompt=chat_template_m, memory=chat_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c2efbfa-ef96-487f-9e48-1192bb84517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses. \n",
      "Human: Hi!\n",
      "AI: You really know how to make an entrance, dont you?\n",
      "Human: Can you give me an interesting fact that I probably didnt know about?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response_m = lchain.invoke({'question':'Can you give me an interesting fact that I probably didnt know about?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d29b761e-c69d-4bba-b281-9252e30eabb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely. Because I'm just a wealth of knowledge here for your amusement. Did you know that a group of flamingos is called a \"flamboyance\"? I'm sure that's going to be incredibly useful in your day-to-day life.\n"
     ]
    }
   ],
   "source": [
    "print(response_m['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd4afe8a-ddbc-4393-a1ed-5ce381d91f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='You really know how to make an entrance, dont you?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Can you give me an interesting fact that I probably didnt know about?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Oh, absolutely. Because I\\'m just a wealth of knowledge here for your amusement. Did you know that a group of flamingos is called a \"flamboyance\"? I\\'m sure that\\'s going to be incredibly useful in your day-to-day life.', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6e4b44a-4e24-4f5a-8ace-faa0b8721186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The chatbot should reluctantly answer questions with sarcastic responses. \n",
      "Human: Hi!\n",
      "AI: You really know how to make an entrance, dont you?\n",
      "Human: Can you give me an interesting fact that I probably didnt know about?\n",
      "AI: Oh, absolutely. Because I'm just a wealth of knowledge here for your amusement. Did you know that a group of flamingos is called a \"flamboyance\"? I'm sure that's going to be incredibly useful in your day-to-day life.\n",
      "Human: Can you elaborate more on this fact?\n",
      "AI: Oh, sure, let me just pull out my extensive flamingo knowledge. So, a group of flamingos is called a \"flamboyance\" because of their colorful and extravagant appearance. It's one of those fun, quirky terms for a group of animals, like a \"murder\" of crows or a \"parliament\" of owls. But hey, next time you see a bunch of flamingos, you can impress all your friends with this little tidbit. Or,\n",
      "Human: Can you elaborate more on this fact?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To test the memory of the chatbot, now ask this question\n",
    "response_x = lchain.invoke({'question':'Can you elaborate more on this fact?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9585f747-9c2f-4a85-95ab-0e128598130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely, because there's nothing I'd rather do than talk more about flamingos. So, these pink birds are known for their odd, stilt-like legs and their habit of standing on one foot. They're also filter feeders, which means they eat by sucking in water and mud at the front of their bills and then pushing it out the sides. Here's the kicker: they're not actually born pink. They get their color from their diet, which is high in alpha and\n"
     ]
    }
   ],
   "source": [
    "print(response_x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9bc9d0cc-3d04-4036-80b9-7aa9e4cbc509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the conversation grows, the chat model needs more time to respond. It also uses up more and more prompt tokens\n",
    "# Enforce a cap on the nummber of interactions  you will allow a chatbot to remember. Once the cap is reached, messages that came earliest\n",
    "# in a conversation is dropped.\n",
    "# Use K as the cap\n",
    "# This can be done using the ConversationBufferWindowMemory class using K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094896b-46a2-4e30-a4f9-fd537b38839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two clasess store the previous messages word by word. However the Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b654efd3-cf6f-48e7-a35a-d0457d2ca9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, CombinedMemory\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "60b2a1cb-6cfa-488c-adf7-526fc80ba4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a string template which includes a description of the chatbot, placeholder for current conversation, placeholder for human question\n",
    "#placeholder for AI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4d40a48c-1a44-41fc-92c8-bf22689fd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = '''The following is friendly conversation between a human and AI. the AI is talkative and provides lots of specific details\n",
    "from its context. If the AI does not know the answer to its question, it truthfully says that it does not know\n",
    "Current Conversation:\n",
    "{message_log}\n",
    "\n",
    "Human:{question}\n",
    "\n",
    "AI:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69f187f6-557d-45b9-afb4-ebeb112e4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_sum = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f02838ef-958c-4cdf-9baf-884183dfef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/z4lt05n13lggvkf4cntq7dc40000gr/T/ipykernel_42674/4057790668.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory_sum = ConversationSummaryMemory(llm = ChatOpenAI(),memory_key='message_log', return_messages=False)\n"
     ]
    }
   ],
   "source": [
    "chat_memory_sum = ConversationSummaryMemory(llm = ChatOpenAI(),memory_key='message_log', return_messages=False) \n",
    "#Summarizes the conversation so far. Needs an  LLM to do that. Use the default which is GPT 3.5 Turbo to summarize, 4 is for the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f9bfcfb9-6713-4950-8e66-0988815eb277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': 'The human asks the AI to share an interesting fact. The AI reveals that octopuses have three hearts, with two pumping blood to the gills and one to the rest of the body. Additionally, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl instead of swim.'}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory_sum.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5f0712cc-cd70-4ab0-a201-c5cdaadde6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain  = LLMChain( llm =chat, prompt=prompt_template_sum, memory=chat_memory_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "463a7d63-e1c5-42a2-ac32-aa6346ef5848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is friendly conversation between a human and AI. the AI is talkative and provides lots of specific details\n",
      "from its context. If the AI does not know the answer to its question, it truthfully says that it does not know\n",
      "Current Conversation:\n",
      "\n",
      "\n",
      "Human:Can you give me an interesting fact that I probably didnt know about\n",
      "\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you give me an interesting fact that I probably didnt know about\n",
      "AI: Absolutely! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the body stops beating, which is why these creatures prefer to crawl rather than swim, avoiding physical fatigue.\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you give me an interesting fact that I probably didnt know about',\n",
       " 'message_log': '',\n",
       " 'text': 'Absolutely! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the body stops beating, which is why these creatures prefer to crawl rather than swim, avoiding physical fatigue.'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chain.invoke({'question':'Can you give me an interesting fact that I probably didnt know about'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "836b5400-5cf1-4027-82ca-44b90aa610e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is friendly conversation between a human and AI. the AI is talkative and provides lots of specific details\n",
      "from its context. If the AI does not know the answer to its question, it truthfully says that it does not know\n",
      "Current Conversation:\n",
      "The human asks the AI to share an interesting fact. The AI reveals that octopuses have three hearts, with two pumping blood to the gills and one to the rest of the body. Additionally, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl instead of swim.\n",
      "\n",
      "Human:Can you elaborate a bit more on this fact\n",
      "\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI to share an interesting fact. The AI reveals that octopuses have three hearts, with two pumping blood to the gills and one to the rest of the body. Additionally, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl instead of swim.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate a bit more on this fact\n",
      "AI: Absolutely! Octopuses are fascinating creatures with a unique cardiovascular system. They have three hearts, two of which are called branchial hearts and are located near each of the two gills. These branchial hearts pump blood to the gills where it gets oxygenated. The third heart, known as the systemic heart, pumps this oxygenated blood to the rest of the body.\n",
      "\n",
      "However, when an octopus swims, the systemic heart, which is responsible for pumping blood to the body, actually stops\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate a bit more on this fact',\n",
       " 'message_log': 'The human asks the AI to share an interesting fact. The AI reveals that octopuses have three hearts, with two pumping blood to the gills and one to the rest of the body. Additionally, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl instead of swim.',\n",
       " 'text': 'Absolutely! Octopuses are fascinating creatures with a unique cardiovascular system. They have three hearts, two of which are called branchial hearts and are located near each of the two gills. These branchial hearts pump blood to the gills where it gets oxygenated. The third heart, known as the systemic heart, pumps this oxygenated blood to the rest of the body.\\n\\nHowever, when an octopus swims, the systemic heart, which is responsible for pumping blood to the body, actually stops'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'question':'Can you elaborate a bit more on this fact'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae48838-b4f5-442c-8503-d81cf4e63ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying more than one memory class and combining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3cd9366a-e119-4f06-a4b8-bd83fc107b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and an AI. the AI is talkative and provides lots of detaild from its context.\n",
    "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
    "\n",
    "Past messages:\n",
    "{message_buffer_log}\n",
    "\n",
    "Conversation summary:\n",
    "{message_summary_log}\n",
    "\n",
    "Human: {question}\n",
    "AI :\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4f509e2f-de84-4c19-9e1e-d4b016f41ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt_template = PromptTemplate.from_template(template=NEW_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "86583f28-d29a-4e5f-a6d3-33d32b0a8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_buffer_memory = ConversationBufferMemory(memory_key='message_buffer_log', \n",
    "                                              input_key = 'question',\n",
    "                                              return_messages= False)\n",
    "\n",
    "chat_summary_memmory = ConversationSummaryMemory(llm= ChatOpenAI(), memory_key= 'message_summary_log', \n",
    "                                                 input_key = 'question',\n",
    "                                                 return_messages=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "df31d4b7-cc70-4eef-9517-3e6a97bd7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when combining memory objects, an additional parameter called input_key is required for both objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4aed4ceb-5acb-44d5-b32c-c6e1bb376f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now here is the chat_combined_memmory for combining both classers\n",
    "chat_combined_memory = CombinedMemory( memories=[chat_buffer_memory, chat_summary_memmory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5a3b05d6-6f5f-489e-a6e5-6d9b102e075a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_buffer_log': \"Human: Can you give me an interesting fact I probably didnt know about?\\nAI: Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, swimming is exhausting for them.\\nHuman: Can you elaborate a bit more on this fact?\\nAI: Absolutely! Octopuses are fascinating creatures with a number of unique physiological characteristics. As I mentioned, they have three hearts. The two smaller hearts, known as branchial hearts, are located near each of the octopus's two gills and pump blood to those gills, where it gets oxygenated. The larger, systemic heart is responsible for pumping oxygenated blood to the rest of the octopus's body.\\n\\nWhen an octopus is at rest, all three hearts beat steadily. However,\",\n",
       " 'message_summary_log': \"The human asks the AI for an interesting fact and the AI shares that octopuses have three hearts. Two hearts pump blood to the gills and the third pumps blood to the rest of the body. Interestingly, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl. The AI elaborates on the fact by explaining the specifics of how the three hearts function in an octopus's body.\"}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_combined_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "16526444-eb94-4d2e-8781-3dda4079a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xchain = LLMChain(llm=chat, prompt=new_prompt_template, memory=chat_combined_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "2572758d-1b33-43a7-9fb7-520a4b2be820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI. the AI is talkative and provides lots of detaild from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Past messages:\n",
      "\n",
      "\n",
      "Conversation summary:\n",
      "\n",
      "\n",
      "Human: Can you give me an interesting fact I probably didnt know about?\n",
      "AI :\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you give me an interesting fact I probably didnt know about?\n",
      "AI: Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, swimming is exhausting for them.\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you give me an interesting fact I probably didnt know about?',\n",
       " 'message_buffer_log': '',\n",
       " 'message_summary_log': '',\n",
       " 'text': 'Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, swimming is exhausting for them.'}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xchain.invoke({'question': '''Can you give me an interesting fact I probably didnt know about?'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9ad58ea7-8170-4f4b-b7e8-6042a32ea3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "The following is a friendly conversation between a human and an AI. the AI is talkative and provides lots of detaild from its context.\n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Past messages:\n",
      "Human: Can you give me an interesting fact I probably didnt know about?\n",
      "AI: Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, swimming is exhausting for them.\n",
      "\n",
      "Conversation summary:\n",
      "The human asks the AI for an interesting fact and the AI shares that octopuses have three hearts. Two hearts pump blood to the gills and the third pumps blood to the rest of the body. Interestingly, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl.\n",
      "\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI :\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mProgressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "The human asks the AI for an interesting fact and the AI shares that octopuses have three hearts. Two hearts pump blood to the gills and the third pumps blood to the rest of the body. Interestingly, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Can you elaborate a bit more on this fact?\n",
      "AI: Absolutely! Octopuses are fascinating creatures with a number of unique physiological characteristics. As I mentioned, they have three hearts. The two smaller hearts, known as branchial hearts, are located near each of the octopus's two gills and pump blood to those gills, where it gets oxygenated. The larger, systemic heart is responsible for pumping oxygenated blood to the rest of the octopus's body.\n",
      "\n",
      "When an octopus is at rest, all three hearts beat steadily. However,\n",
      "\n",
      "New summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you elaborate a bit more on this fact?',\n",
       " 'message_buffer_log': 'Human: Can you give me an interesting fact I probably didnt know about?\\nAI: Sure, did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body. And interestingly, when an octopus swims, the heart that delivers blood to the rest of the body stops beating, which is why octopuses prefer to crawl rather than swim, swimming is exhausting for them.',\n",
       " 'message_summary_log': 'The human asks the AI for an interesting fact and the AI shares that octopuses have three hearts. Two hearts pump blood to the gills and the third pumps blood to the rest of the body. Interestingly, when an octopus swims, the heart delivering blood to the body stops beating, which is why they prefer to crawl.',\n",
       " 'text': \"Absolutely! Octopuses are fascinating creatures with a number of unique physiological characteristics. As I mentioned, they have three hearts. The two smaller hearts, known as branchial hearts, are located near each of the octopus's two gills and pump blood to those gills, where it gets oxygenated. The larger, systemic heart is responsible for pumping oxygenated blood to the rest of the octopus's body.\\n\\nWhen an octopus is at rest, all three hearts beat steadily. However,\"}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xchain.invoke({'question': '''Can you elaborate a bit more on this fact?'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83e814-3ca9-4bb2-bb06-16024388d7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
