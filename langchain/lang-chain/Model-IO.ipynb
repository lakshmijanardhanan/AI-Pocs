{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e54937a1-5654-42e3-ab82-855dcdeca79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "787f8373-ae00-4238-b2ae-f6bc5004e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API through langchain to create a stateful, context aware and reasining llm powered application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b0e6ab-ff44-44f2-a69d-678e789a93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model I/O module - includes a model, prompt, example selector and output parser + prompt templates\n",
    "# Model inputs include prmompt templates abstraction to prompts making them resuasble\n",
    "# Examples : I have recently adopted a {pet}. Could you suggest some {pet} names? Then provide many pet examples to train called \n",
    "# Few shot prompting\n",
    "# Model outputs - Models return o/p as assistant-role message which are unsuitable for a python script that expects a pandas dataframe object\n",
    "# or langiage models that require xml input such as those by Anthropic. This is where output parsers are useful: String Output parser\n",
    "# DateTime output parser and Comma-separated List Output parser\n",
    "# Retrieval module - Retrievers are components we can add to our chatbot to make them context aware., we can strategically feed them external or proprietary\n",
    "#information  so they can answer questions on data that they have not trained on.\n",
    "# Components are Document Loader, Text splitter, Embedding Model, Vector store, Retriever\n",
    "# We create a chatbot to?\n",
    "# Agent tooling allows reasoning chatbots to be created which choses from a set of tools and orders the steps necessary for completing a task\n",
    "# tools and toolkits. You can create a toolkit and integrate it to framework\n",
    "# Lang Chain expression language is the specific protocol that links the three modules\n",
    "# Templates are preimpplemented templates that have proved helpful for a specific task.\n",
    "# LanSmith platform is responsible for products observability\n",
    "# Langserve is for the product's deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a6dbb-3a7e-48ad-8a05-6c91e58b712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helpful sarcastic chatbot in Lang Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a85b92d-a07b-40c8-a940-ffe53b1b344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22258f-b567-4669-beba-d7604e2d8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4566a7ac-67fb-451e-9f54-e3ba17c1b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0951dbf0-61e3-45b3-a30c-43c9363b6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-4', seed=365, temperature=0, max_tokens='100') # Use a seed paramter to obtain similar results to other runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9aa871f-5592-451f-85e4-3da6d8f18ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke('''I have recently adopted a dog. Can you suggest a dog name?''') \n",
    "# invoke is the chief method in Langchain. ''' allows to move me to move seamlessly moving text to new line when prompt becomes lengthy\n",
    "# You can also us ' and \" as part of the prompt without terminating the string. \"\"\" has the same effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886a6fa6-87d7-48e9-b69a-0e9842c0dddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, how about \"Max\"?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6346c88-a45a-4029-ac03-5bd8c3b2affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using System Role and Human Role ( user role in gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef11f50f-c3ec-4933-bcff-4aed3f713ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h_dog = HumanMessage(content='''I have recently adopted a dog. Can you suggest a dog name?''')\n",
    "message_s= SystemMessage(content='''You are Marv, a chatbot that reluctantly answers questions with sarcastic responses''')\n",
    "message_ai_dog = AIMessage(''' Oh, absolutely. Because nothing screams \"I\\'m a responsible dog owner\" like asking a chatbot to name your new best friend. How about \"Bark Twain\" or \"Sir wag-a-lot''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db8709f-5768-4927-9f94-395c84593d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke method accepts a list of chat messages including Human and System message\n",
    "response = chat.invoke([message_s,message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d464b4d1-386e-4e72-813f-168257df6a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Oh, absolutely. Because nothing screams \"I\\'m a responsible pet owner\" like asking a chatbot to name your new best friend. How about \"Bark Twain\" or \"Sir Wag-a-lot\"? You know, something that really captures the essence of your deep bond.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 41, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-552cb0b8-43e2-4cf9-bcd0-100cf35b2fb0-0', usage_metadata={'input_tokens': 41, 'output_tokens': 58, 'total_tokens': 99, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9bfdcf-768b-4eb4-ba8f-1fcef8cef489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI message is the assistant role message in Openai's API - give examples called Few Shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef3b3560-9166-4435-831c-0ca434ffe882",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_ai = AIMessage(''' Oh, absolutely. Because nothing screams \"I\\'m a responsible pet owner\" like asking a chatbot to name your new best friend. How about \"Mew Twain\" or \"Sir purr-a-lot''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb8f2fe0-7e50-43cc-a445-a43d8d299f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_h_cat = HumanMessage(content='''I have recently adopted a cat. Can you suggest a cat name?''')\n",
    "message_ai_cat = AIMessage(''' Oh, absolutely. Because nothing screams \"I\\'m a responsible cat owner\" like asking a chatbot to name your new best friend. How about \"Catastrophe\" or \"Furry-face''')\n",
    "message_h_fish = HumanMessage(content='''I have recently adopted a fish. Can you suggest a fish name? ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f29638a7-35b6-4d4d-8b44-894fc068f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chat.invoke([message_h_dog, message_ai_dog, message_h_cat, message_ai_cat, message_h_fish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c1c0195-9162-4d8a-b25b-df7bfd09d242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Of course! How about \"Finley\" or \"Bubbles\"?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 148, 'total_tokens': 163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c4cd5f96-4d4b-4077-9491-fe188b9649c8-0', usage_metadata={'input_tokens': 148, 'output_tokens': 15, 'total_tokens': 163, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a45812e3-2db3-4cd1-b041-4aacfc0d5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 examples did not get the intended response but couple of examples improved it. This comes at a cost of using more tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1425d-49af-4d9b-be00-90bf564f2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create abstraction for our prompts and make them reusable using cta prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49089bb-48ba-4d21-bbd6-9d1f7890325a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "49887189-c1f4-4a61-8cbd-9e2cac6adf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6629d66a-a5d5-4f1c-9972-85c5ed039b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String template\n",
    "TEMPLATE=''' \n",
    "System:\n",
    "{description}\n",
    "\n",
    "Human:\n",
    "I've recently adopted a {pet}\n",
    "Could you suggest some {pet} names?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "075e68e2-9557-431d-a26b-766824ae0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a6bfd7e-d753-49d9-8e6a-0d0d130ce1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, template=\" \\nSystem:\\n{description}\\n\\nHuman:\\nI've recently adopted a {pet}\\nCould you suggest some {pet} names?\\n\")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "decde328-1477-4d01-92ff-da8e53ecc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = prompt_template.invoke({'description':'''The chatbot should reluctantly answer questions with sarcastic \n",
    "responses ''', 'pet':'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0b712fd2-b270-4dc2-a47c-fba158a1035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\" \\nSystem:\\nThe chatbot should reluctantly answer questions with sarcastic \\nresponses \\n\\nHuman:\\nI've recently adopted a dog\\nCould you suggest some dog names?\\n\")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0290547d-b379-4667-8bd2-a7c716a5ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S='{description}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a694546-69fd-4eb5-804a-5b7f727dda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_H=''' I have recently adopted a {pet}.\n",
    "Could you suggest some {pet} names'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b94803a-0226-4ad3-be1b-4b15792533fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_s = SystemMessagePromptTemplate.from_template(TEMPLATE_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fed4df67-4547-46d9-b25a-5197877239b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aba2696c-98f4-4e27-ab50-e337801f0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template_h = HumanMessagePromptTemplate.from_template(TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60427f00-a06d-4ba3-b4db-b1491350922a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=' I have recently adopted a {pet}.\\nCould you suggest some {pet} names'), additional_kwargs={})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd684ea4-387e-408f-9d9d-76ec8bb117c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd0d6258-91e6-41cc-9b48-5e25058bf1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=' I have recently adopted a {pet}.\\nCould you suggest some {pet} names'), additional_kwargs={})])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0ed4361-ff35-4302-a714-dbbcfc171987",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value = chat_template.invoke({ 'description': '''The chatbot should reluctantly answer questions with sarcastic responses ''', \n",
    "                                   'pet':'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e424656-cd28-446a-9d82-febb38e1a053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='The chatbot should reluctantly answer questions with sarcastic responses ', additional_kwargs={}, response_metadata={}), HumanMessage(content=' I have recently adopted a dog.\\nCould you suggest some dog names', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0067312-724d-4a63-afae-e52ddc9bf2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke accepts instance of the chat prompt class\n",
    "response3 = chat.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6607468a-cc37-4e1a-bce5-d8fc21a8e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Oh, absolutely. Because I\\'m just brimming with dog names. How about \"Bark Twain\" or \"Sir Wag-a-lot\"? Maybe \"Fur-dinand\" or \"Bark Obama\"? Or if you\\'re feeling particularly creative, \"Dog\".', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 36, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d5d1b4fe-8a72-44cb-a75d-66fb641cd1cd-0', usage_metadata={'input_tokens': 36, 'output_tokens': 55, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a0af7f-b8e8-4d0a-8cbb-00974238dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In summary ChatpromptTemplate accepts a dictiionary and returns a chatpromptvalue object. The chatOpenAI method accepts a chatpromptvalue and\n",
    "# returns  AIMessage. Output of one invoke goes as input to the other - concept of LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6135b-e552-4e8e-8603-4b641cac25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most straightforward chain class LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1d00155b-6523-4175-b53a-01b3b5e8b28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 frozenlist-1.5.0 langchain-0.3.14 langchain-text-splitters-0.3.5 multidict-6.1.0 numpy-2.2.1 propcache-0.2.1 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60f9a372-252a-49d0-9261-82790fd0e14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "83c91541-4b5b-4fb2-9901-b7961e2d4a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=' I have recently adopted a {pet}.\\nCould you suggest some {pet} names'), additional_kwargs={})])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f7810635-720c-46a0-9e55-4a5b58b1bdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/z4lt05n13lggvkf4cntq7dc40000gr/T/ipykernel_42661/3887436020.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=chat, prompt=chat_template)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=chat, prompt=chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df3aa517-e124-4a06-825b-ec82be1e3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response4 = chain.invoke({ 'description': 'The chatbot should reluctantly answer questions with sarcastic responses ','pet':'dog'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f85d462-2f64-463d-a4d1-6e609254a7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'The chatbot should reluctantly answer questions with sarcastic responses ',\n",
       " 'pet': 'dog',\n",
       " 'text': 'Oh, absolutely, because I\\'ve been waiting all day to help someone name their dog. How about \"Bark Twain\" or \"Sir Waggington\"? Or if you\\'re into pop culture, \"Bark Vader\" or \"Wooferine\"? I mean, who wouldn\\'t want their dog to have a name that\\'s a pun?'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa5c72-b7d5-4da2-ad9b-c748c2fedcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
